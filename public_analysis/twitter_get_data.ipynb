{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3437c05",
   "metadata": {
    "id": "e3437c05",
    "outputId": "c88d3681-214d-4ea7-deab-962017f99e95",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gensim in c:\\users\\lisannal\\anaconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\lisannal\\anaconda3\\lib\\site-packages (from gensim) (1.9.3)\n",
      "Requirement already satisfied: Cython==0.29.28 in c:\\users\\lisannal\\anaconda3\\lib\\site-packages (from gensim) (0.29.28)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\lisannal\\anaconda3\\lib\\site-packages (from gensim) (1.23.4)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\lisannal\\anaconda3\\lib\\site-packages (from gensim) (6.0.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip install tweepy\n",
    "#!pip install configparser\n",
    "#!pip install wordcloud\n",
    "#!pip install nltk\n",
    "#!pip install textblob\n",
    "#!pip install estnltk==1.7.1\n",
    "#!pip install gensim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30752b93",
   "metadata": {
    "id": "30752b93"
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import re\n",
    "import csv\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import math\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681b5bb4",
   "metadata": {
    "id": "681b5bb4"
   },
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c20b5f",
   "metadata": {
    "id": "3b875b14"
   },
   "outputs": [],
   "source": [
    "import configparser\n",
    "config = configparser.RawConfigParser()\n",
    "config.read('tweet.ini')\n",
    "api_key = config['twitter']['api_key']\n",
    "api_key_secret = config['twitter']['api_key_secret']\n",
    "bearer_token =  config['twitter']['bearer_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e63938e",
   "metadata": {
    "id": "5e63938e"
   },
   "source": [
    "## Tweepy setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0784c0d5",
   "metadata": {
    "id": "0784c0d5"
   },
   "source": [
    "- API guide: https://dev.to/twitterdev/a-comprehensive-guide-for-using-the-twitter-api-v2-using-tweepy-in-python-15d9  \n",
    "- Tweepy Documentation: https://docs.tweepy.org/en/stable/index.html   \n",
    "- Twitter API v2 data dictionary: https://developer.twitter.com/en/docs/twitter-api/data-dictionary/object-model/tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d929d9c",
   "metadata": {
    "id": "4d929d9c"
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "client = tweepy.Client(bearer_token, wait_on_rate_limit = True)\n",
    "\n",
    "auth = tweepy.OAuth2BearerHandler(bearer_token)\n",
    "api = tweepy.API(auth, wait_on_rate_limit= True, retry_count=12, retry_delay=5, retry_errors=set([503, 500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9878c38d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "232"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_usernames = list(pd.read_csv('valid_twitter_usernames.csv')[\"0\"])\n",
    "len(valid_usernames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f58a22fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_pattern = re.compile(\"[\"\n",
    "         u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "         u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "         u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "         u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "         u\"\\U00002702-\\U000027B0\"\n",
    "         u\"\\U000024C2-\\U0001F251\"\n",
    "         \"]+\", flags=re.UNICODE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f002fc",
   "metadata": {},
   "source": [
    "# Leaders data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b1832076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def queryFunction(usernames, start_interval, end_interval, csvWriter):\n",
    "    idx = 0\n",
    "    for username in usernames:\n",
    "        if idx % 10 == 0:\n",
    "            print(\"On user\", str(idx) , \"Current time is\", str(datetime.datetime.now()))\n",
    "            \n",
    "\n",
    "        idx += 1\n",
    "        \n",
    "        query = 'from:' + username\n",
    "        for response in tweepy.Paginator(client.search_all_tweets,\n",
    "                                         query=query, \n",
    "                                         tweet_fields=['lang', 'public_metrics', 'created_at'],\n",
    "                                         start_time=start_interval,\n",
    "                                         end_time =end_interval,  \n",
    "                                         max_results=500):\n",
    "            time.sleep(1)\n",
    "            if (response.data != None):\n",
    "                for tweet in response.data:\n",
    "                    tweetText = emoji_pattern.sub(r'', tweet.text)\n",
    "                    retweet_count = 0\n",
    "                    reply_count = 0\n",
    "                    like_count = 0\n",
    "                    quote_count = 0\n",
    "                    impression_count = 0\n",
    "                    if tweet.public_metrics:\n",
    "                        retweet_count = tweet.public_metrics['retweet_count']\n",
    "                        reply_count = tweet.public_metrics['reply_count']\n",
    "                        like_count = tweet.public_metrics['like_count']\n",
    "                        quote_count = tweet.public_metrics['quote_count']\n",
    "                        impression_count = tweet.public_metrics['impression_count']\n",
    "\n",
    "                    csvWriter.writerow([username, tweet.id, tweetText, tweet.lang, start_interval, end_interval, retweet_count, reply_count, like_count, quote_count, impression_count, tweet.created_at])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "60d131e1",
   "metadata": {
    "id": "60d131e1",
    "outputId": "fea30585-0c51-4a65-f81e-e9170ef7864a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total users 11\n",
      "Total interval 1\n",
      "----------------------------------------------------------\n",
      "Starting with interval number 0\n",
      "Current time 2023-03-01 17:05:47.233417\n",
      "----------------------------------------------------------\n",
      "On user 0 Current time is 2023-03-01 17:05:47.237952\n",
      "On user 10 Current time is 2023-03-01 17:06:01.706667\n",
      "----------------------------------------------------------\n",
      "Finsihed writing\n",
      "Current time 2023-03-01 17:06:02.942298\n",
      "--- 15.718170881271362 seconds ---\n"
     ]
    }
   ],
   "source": [
    "# set up csvWriter\n",
    "header_row = ['user', 'tweet_id', 'tweet_text', 'tweet_lang', 'start', 'end', 'retweet_count', 'reply_count',\n",
    "                        'like_count', 'quote_count', 'impression_count', 'created_at']\n",
    "\n",
    "# define users and timeframes\n",
    "usernames = valid_usernames\n",
    "\n",
    "time_intervals = [\n",
    "    #['2022-01-01T00:00:00.000Z','2022-01-31T23:59:00.000Z'], \n",
    "    #['2022-02-01T00:00:00.000Z','2022-02-28T23:59:00.000Z'], \n",
    "    #['2022-03-01T00:00:00.000Z','2022-03-31T23:59:00.000Z'], \n",
    "    #['2022-04-01T00:00:00.000Z','2022-04-30T23:59:00.000Z'],\n",
    "    #['2022-05-01T00:00:00.000Z','2022-05-31T23:59:00.000Z'], \n",
    "    #['2022-06-01T00:00:00.000Z','2022-06-30T23:59:00.000Z'], \n",
    "    #['2022-07-01T00:00:00.000Z','2022-07-31T23:59:00.000Z'], \n",
    "    #['2022-08-01T00:00:00.000Z','2022-08-31T23:59:00.000Z'], \n",
    "    #['2022-09-01T00:00:00.000Z','2022-09-30T23:59:00.000Z'], \n",
    "    #['2022-10-01T00:00:00.000Z','2022-10-31T23:59:00.000Z'], \n",
    "    #['2022-11-01T00:00:00.000Z','2022-11-30T23:59:00.000Z'], \n",
    "    #['2022-12-01T00:00:00.000Z','2022-12-31T23:59:00.000Z'], \n",
    "    #['2023-01-01T00:00:00.000Z','2023-01-31T23:59:00.000Z'],\n",
    "    ['2023-02-01T00:00:00.000Z','2023-02-28T23:59:00.000Z'],\n",
    "]\n",
    "\n",
    "#time_intervals = [['2022-02-21T23:59:00.000Z', '2022-03-31T23:59:00.000Z']] ## get missing data\n",
    "\n",
    "# start counting time\n",
    "start_time = time.time()\n",
    "\n",
    "print('Total users', str(len(usernames)))\n",
    "print('Total interval', str(len(time_intervals)))\n",
    "\n",
    "# fetch the tweets\n",
    "interval_counter = 0\n",
    "for time_interval in time_intervals:\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(\"Starting with interval number \" + str(interval_counter))\n",
    "    print(\"Current time \" + str(datetime.datetime.now()))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    start_interval = time_interval[0]\n",
    "    end_interval = time_interval[1]\n",
    "    \n",
    "    fileName = \"new_data_24_02/interval_01_03_\" + str(interval_counter) + \"_from_\" + str(start_interval).replace(\":\", \"-\") + \"_until_\" + str(end_interval).replace(\":\", \"-\") + \".csv\"\n",
    "    interval_counter += 1\n",
    "    with open(fileName, 'a+', encoding=\"utf-8\") as csvFile:\n",
    "        csvWriter = csv.writer(csvFile)\n",
    "        csvWriter.writerow(header_row)\n",
    "        queryFunction(usernames, start_interval, end_interval, csvWriter)\n",
    "    \n",
    "    \n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(\"Finsihed writing\")\n",
    "    print(\"Current time \" + str(datetime.datetime.now()))\n",
    "    \n",
    "   \n",
    " # end counting time\n",
    "end_time = time.time()                   \n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda879ba",
   "metadata": {},
   "source": [
    "# Public data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8fa73a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'sõda' # war\n",
    "for response in tweepy.Paginator(client.get_all_tweets_count, query=query, start_time='2022-02-23T16:12:22.000Z'):\n",
    "    print(response)\n",
    "    print(response.meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00a27b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response(data=[<Tweet id=1513900133397975041 text='RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…'>, <Tweet id=1513899082431012867 text='RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…'>, <Tweet id=1513898200201142272 text='RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…'>, <Tweet id=1513897535592611843 text='Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik, kes oli sõja alguses töötanud Kiievi tipphotellis, ning uuris tööle saamise võimalusi - täna liitus meiega. Julge pealehakkamine on enam kui pool võitu! 🇺🇦👏'>, <Tweet id=1506900160672059392 text='Venekeelset kooli eelistav Ukraina põgenik, kui kuuleb, et vene koolides võib ka putiniste olla. Nendele inimestele tuleks kiiresti selgeks teha, mis vahe on eesti ja vene koolil, lisaks keelele. https://t.co/0E0iL1jNQ0'>, <Tweet id=1506218985267900421 text='RT @jaakennuste: Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused…'>, <Tweet id=1506164075402825733 text='RT @jaakennuste: Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused…'>, <Tweet id=1505932126843195398 text='Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused ja õige suhtumine. Tema kodulinn Mariupol on maatasa pommitatud Putini sõjaväe poolt. https://t.co/lGeym29suT'>, <Tweet id=1501955994997379073 text='Naine (põgenik) Ukraina-Poola piiril: \"1941 hukkus mu vanaisa, kaitstes Venemaad Sakslate eest. Nüüd põgenen Saksamaale, kes kaitseb mind venelaste eest\"\\n\\nLogo: Internetist https://t.co/NFMVDB0WY7'>, <Tweet id=1500004453881200641 text='Väike põgenik Ukraina-Poola piiril. #Ukraine https://t.co/hKF6alpQmD'>], includes={'users': [<User id=14175289 name=Kris Haamer 漢默可 🇪🇪🇺🇦🇹🇼 username=krishaamer>, <User id=27720656 name=Risto Solman username=rixsol>, <User id=1500138618261839872 name=SvenX 🇪🇪 🇺🇦 username=Sven7966>, <User id=105584517 name=Viljar Arakas username=viljararakas>, <User id=2766392466 name=TSinisaar username=tsinisaar>, <User id=744105687484084224 name=Vadimurm username=vadurmest>, <User id=111371654 name=💉💉💉💉💉-M- #longcovid (2y +) lyme&co (10y) username=MayMunich>, <User id=16311917 name=Jaak username=jaakennuste>, <User id=1198416960 name=Urmas Paet username=Urmaspaet>]}, errors=[], meta={'newest_id': '1513900133397975041', 'oldest_id': '1500004453881200641', 'result_count': 10})\n",
      "---------\n",
      "[<Tweet id=1513900133397975041 text='RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…'>, <Tweet id=1513899082431012867 text='RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…'>, <Tweet id=1513898200201142272 text='RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…'>, <Tweet id=1513897535592611843 text='Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik, kes oli sõja alguses töötanud Kiievi tipphotellis, ning uuris tööle saamise võimalusi - täna liitus meiega. Julge pealehakkamine on enam kui pool võitu! 🇺🇦👏'>, <Tweet id=1506900160672059392 text='Venekeelset kooli eelistav Ukraina põgenik, kui kuuleb, et vene koolides võib ka putiniste olla. Nendele inimestele tuleks kiiresti selgeks teha, mis vahe on eesti ja vene koolil, lisaks keelele. https://t.co/0E0iL1jNQ0'>, <Tweet id=1506218985267900421 text='RT @jaakennuste: Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused…'>, <Tweet id=1506164075402825733 text='RT @jaakennuste: Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused…'>, <Tweet id=1505932126843195398 text='Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused ja õige suhtumine. Tema kodulinn Mariupol on maatasa pommitatud Putini sõjaväe poolt. https://t.co/lGeym29suT'>, <Tweet id=1501955994997379073 text='Naine (põgenik) Ukraina-Poola piiril: \"1941 hukkus mu vanaisa, kaitstes Venemaad Sakslate eest. Nüüd põgenen Saksamaale, kes kaitseb mind venelaste eest\"\\n\\nLogo: Internetist https://t.co/NFMVDB0WY7'>, <Tweet id=1500004453881200641 text='Väike põgenik Ukraina-Poola piiril. #Ukraine https://t.co/hKF6alpQmD'>]\n",
      "-------\n",
      "RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "query = 'ukraina põgenik'\n",
    "\n",
    "tweets = client.search_all_tweets(query=query, \n",
    "                                  tweet_fields=['lang','author_id', 'created_at', 'public_metrics', 'geo', 'referenced_tweets' ], \n",
    "                                  expansions=[\"author_id\"],\n",
    "                                  user_fields=['username', 'location', 'id', 'protected', 'public_metrics', 'verified'],\n",
    "                                  start_time='2022-02-23T16:12:22.000Z', \n",
    "                                  end_time = '2022-05-31T16:12:22.000Z',  \n",
    "                                  max_results=10)\n",
    "\n",
    "print(tweets)\n",
    "print('---------')\n",
    "print(tweets.data)\n",
    "print('-------')\n",
    "print(tweets.data[0].text)\n",
    "\n",
    "#for tweet in tweets.data:\n",
    "    #print(tweet.text)\n",
    "    #if len(tweet.context_annotations) > 0:\n",
    "    #    print(tweet.context_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c3b0d4f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'et'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.data[0].lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ab33702",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retweeted'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.data[0].referenced_tweets[0].type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a1978227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.data[4].referenced_tweets == None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3289a400",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retweet_count': 3,\n",
       " 'reply_count': 0,\n",
       " 'like_count': 0,\n",
       " 'quote_count': 0,\n",
       " 'impression_count': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.data[0].public_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "95919b71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14175289"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets.includes['users'][0].public_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2f8b8703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets[1]['users'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b6aed6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…\n",
      "RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…\n",
      "RT @viljararakas: Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik,…\n",
      "Personali värbamise juures oli üks äärmiselt südamlik lugu. Päev tagasi jalutas hotelli peauksest sisse Ukraina põgenik, kes oli sõja alguses töötanud Kiievi tipphotellis, ning uuris tööle saamise võimalusi - täna liitus meiega. Julge pealehakkamine on enam kui pool võitu! 🇺🇦👏\n",
      "Venekeelset kooli eelistav Ukraina põgenik, kui kuuleb, et vene koolides võib ka putiniste olla. Nendele inimestele tuleks kiiresti selgeks teha, mis vahe on eesti ja vene koolil, lisaks keelele. https://t.co/0E0iL1jNQ0\n",
      "RT @jaakennuste: Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused…\n",
      "RT @jaakennuste: Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused…\n",
      "Võtsime täna tööle esimese Ukraina põgeniku. Mitte ainult seepärast, et ta on põgenik. Võtsime kuna tal erialased oskused ja õige suhtumine. Tema kodulinn Mariupol on maatasa pommitatud Putini sõjaväe poolt. https://t.co/lGeym29suT\n",
      "Naine (põgenik) Ukraina-Poola piiril: \"1941 hukkus mu vanaisa, kaitstes Venemaad Sakslate eest. Nüüd põgenen Saksamaale, kes kaitseb mind venelaste eest\"\n",
      "\n",
      "Logo: Internetist https://t.co/NFMVDB0WY7\n",
      "Väike põgenik Ukraina-Poola piiril. #Ukraine https://t.co/hKF6alpQmD\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "for t in tweets.data:\n",
    "    print(t)\n",
    "    \n",
    "for u in tweets.includes['users']:\n",
    "    print(u.verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1ef648c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def isRetweet(referenced_tweets):\n",
    "    hasRetweet = False\n",
    "    if referenced_tweets != None:\n",
    "        for reference in referenced_tweets:\n",
    "            if reference.type == 'retweeted':\n",
    "                hasRetweet = True\n",
    "                break\n",
    "                \n",
    "        return hasRetweet\n",
    "    else:\n",
    "        return False\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "382de056",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_tweet_fields = ['lang','author_id', 'created_at', 'public_metrics', 'geo', 'referenced_tweets' ]\n",
    "var_user_fields = ['username', 'id', 'public_metrics']\n",
    "\n",
    "header_row_tweet = ['tweet_id', 'author_id', 'tweet_text', 'tweet_lang','created_at', 'geo', 'isRetweet', 'retweet_count', 'reply_count',\n",
    "                        'like_count', 'quote_count', 'impression_count']\n",
    "\n",
    "header_row_user = ['id', 'username', 'followers_count', 'following_count',\n",
    "                        'tweet_count', 'listed_count']\n",
    "\n",
    "def queryTweets(query,csvTweetWriter, csvUserWriter):\n",
    "    for response in tweepy.Paginator(client.search_all_tweets,\n",
    "                                      query=query, \n",
    "                                      tweet_fields=var_tweet_fields, \n",
    "                                      expansions=[\"author_id\"],\n",
    "                                      user_fields=var_user_fields,\n",
    "                                      start_time='2022-01-01T00:00:00.000Z', \n",
    "                                      end_time = '2023-01-31T23:59:00.000Z',  \n",
    "                                      max_results=500):\n",
    "        time.sleep(1)\n",
    "        if (response.data != None):\n",
    "            for tweet in response.data:\n",
    "                tweetText = emoji_pattern.sub(r'', tweet.text)\n",
    "                retweet_count = 0\n",
    "                reply_count = 0\n",
    "                like_count = 0\n",
    "                quote_count = 0\n",
    "                impression_count = 0\n",
    "                retweet = isRetweet(tweet.referenced_tweets)\n",
    "                \n",
    "                if tweet.public_metrics:\n",
    "                    retweet_count = tweet.public_metrics['retweet_count']\n",
    "                    reply_count = tweet.public_metrics['reply_count']\n",
    "                    like_count = tweet.public_metrics['like_count']\n",
    "                    quote_count = tweet.public_metrics['quote_count']\n",
    "                    impression_count = tweet.public_metrics['impression_count']\n",
    "                csvTweetWriter.writerow([tweet.id, tweet.author_id, tweetText, tweet.lang, tweet.created_at, tweet.geo, retweet, retweet_count, reply_count, like_count, quote_count, impression_count])\n",
    "        \n",
    "        if ('users' in response[1]):\n",
    "            for user in response.includes['users']:\n",
    "                followers_count = 0\n",
    "                following_count = 0\n",
    "                tweet_count = 0\n",
    "                listed_count = 0\n",
    "                if user.public_metrics:\n",
    "                    if followers_count in user.public_metrics:\n",
    "                        followers_count = user.public_metrics['followers_count']\n",
    "                    if following_count in user.public_metrics:\n",
    "                        following_count = user.public_metrics['following_count']\n",
    "                    if tweet_count in user.public_metrics:\n",
    "                        tweet_count = user.public_metrics['tweet_count']\n",
    "                    if listed_count in user.public_metrics:\n",
    "                        listed_count = user.public_metrics['listed_count']\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "                \n",
    "                csvUserWriter.writerow([user.id, user.username,followers_count, following_count,\n",
    "                        tweet_count, listed_count])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9c19d165",
   "metadata": {},
   "outputs": [],
   "source": [
    "##keywords_est = ['ukraina', 'ua', 'ukrainlane', 'põgenik', 'venemaa', 'sõda', 'konflikt', 'lääs', 'lääneriigid', 'agressioon', \n",
    "##                'agressor','nato', 'sõjapõgenik', 'pagulane', 'migrant']\n",
    "\n",
    "#uasoda = ['ukraina sõda', 'ukraina sõja', 'ukraina sõjas', 'ukraina sõjast', 'ukraina sõjaks', 'ukraiana sõjalt', 'ukraina sõjal', 'ukraina sõjale','ukraina sõjani', 'ukraina sõjaga']\n",
    "#uapogenik = ['ukraina põgenik', 'ukraina põgeniku', 'ukraina põgenikku', 'ukraina põgenikule', 'ukraina põgenikust', 'ukraina põgenikuks', 'ukraina põgenikuna']\n",
    "#uaother = ['ukraina venemaa','ukraina konflikt', 'ukraina aggressioon', 'venemaa agressioon']\n",
    "#uaotherpogenik = ['ukraina pagulane', 'ukraina migrant', 'ukraina sõjapõgenik', 'ukraina sõjapõgeniku']\n",
    "\n",
    "#venemaa = ['venemaa agressioon', 'venemaa agressor', 'venemaa agressiooni', 'venemaa putin', 'venemaa sõda', 'venemaa erioperatsioon', 'venemaa putini', 'venemaa putinil']\n",
    "\n",
    "#ua_positive = [ 'ukraina abi', 'ukraina toetus', 'ukraina koostöö', 'ukraina toetamine']\n",
    "\n",
    "giant = ['ukraina', 'ua', 'ukrainlane', 'põgenik', 'venemaa', 'sõda', 'konflikt', 'lääs', 'lääneriigid', 'agressioon', \n",
    "                'agressor','nato', 'sõjapõgenik', 'pagulane', 'migrant']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef347026",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "#words.concat(uasoda).concat(uapogenik).concat(uaother).concat(uaotherpogenik).concat(venemaa).concat(ua_positive)\n",
    "words = [] + uaotherpogenik + venemaa + ua_positive + giant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2cf3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cccf348a",
   "metadata": {},
   "outputs": [],
   "source": [
    "giant2 = ['ukrainlane', 'põgenik', 'sõjapõgenik', 'sõda', 'lääs', 'lääneriigid','pagulane ukraina',\n",
    "          'venemaa','agressioon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8a293ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "venemaa2 = ['venemaa sanktsioon', 'venemaa ründama', 'venemaa ründamine', 'venemaa agressor','venemaa ründas', 'venemaa rünnak',\n",
    "           'venemaa konflikt', 'putini sõda']\n",
    "\n",
    "ukraina = ['ukraina liitlane', 'ukraina sanktsioon', 'ukraina ründama', 'ukraina ründas', 'ukraina rünnak', 'ukraina julgeolek',\n",
    "          'lääs ukraina', 'immigratsioon ukraina', 'ukraina agressor', 'ukraina elu eesti', 'varjupaiga ukraina', \n",
    "             'varjupaik ukraina']\n",
    "\n",
    "uainimene = ['ukraina inimene', 'ukraina inimese', 'ukraina inimeste', 'ukraina inimestel', 'ukraina inimestega', \n",
    "             'ukraina inimestest', 'ukraina inimest', 'ukraina inimesele', 'ukraina inimesena', 'ukraina inimesega']\n",
    "\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8a9e3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = []\n",
    "#words.concat(uasoda).concat(uapogenik).concat(uaother).concat(uaotherpogenik).concat(venemaa).concat(ua_positive)\n",
    "words2 = [] + venemaa2 + ukraina + uainimene + giant2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e68504a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59dad3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ukraina and sõda keywords are half done - crashed for some reasons\n",
    "words3 = ['venemaa putin', 'ukraina putin', 'ukraina putini', 'sõda putin', 'sõjakuritegu', 'sõjakuriteod', 'ukraina erioperatsioon',\n",
    "          'ukraina vabastamine', 'ukraina vaba',\n",
    "          'lääneriigid','pagulane ukraina','lääs', 'venemaa','agressioon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a495cde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "words4 = [\"eesti ukraina\", \"eesti venemaa\", \"eesti putin\", \"\\\"sõda\\\" lang:et\", \"ukraina lang:et\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a6f735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "words5 = [\"\\\"sõda\\\" lang:et\", \"ukraina lang:et\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a903f07b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total keywords 2\n",
      "----------------------------------------------------------\n",
      "Starting with keyword number 1: \"sõda\" lang:et\n",
      "Current time 2023-02-05 22:54:00.654513\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "Finsihed writing\n",
      "Current time 2023-02-05 22:56:10.576553\n",
      "----------------------------------------------------------\n",
      "Starting with keyword number 2: ukraina lang:et\n",
      "Current time 2023-02-05 22:56:10.576553\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "Finsihed writing\n",
      "Current time 2023-02-05 22:59:37.082870\n",
      "--- 336.42835688591003 seconds ---\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "print('Total keywords', str(len(words5)))\n",
    "\n",
    "# fetch the tweets\n",
    "keyword_counter = 1\n",
    "for keyword in words5: # word lists here\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(\"Starting with keyword number \" + str(keyword_counter) +\": \" + str(keyword))\n",
    "    print(\"Current time \" + str(datetime.datetime.now()))\n",
    "    print(\"----------------------------------------------------------\")\n",
    "    \n",
    "    tweetFileName = \"keywords_data/tweet_keyword_\" + keyword.replace('\"', '') + \".csv\"\n",
    "    userFileName = \"users_data/user_keyword_\" + keyword.replace('\"', '') + \".csv\"\n",
    "    keyword_counter += 1\n",
    "    \n",
    "    tweet_file = open(tweetFileName, 'a+', encoding=\"utf-8\")\n",
    "    user_file = open(userFileName, 'a+', encoding=\"utf-8\")\n",
    "    \n",
    "    tweetWriter = csv.writer(tweet_file)\n",
    "    userWriter = csv.writer(user_file)\n",
    "    \n",
    "    queryTweets(keyword,tweetWriter, userWriter)\n",
    "\n",
    "    tweet_file.close()\n",
    "    user_file.close()\n",
    "    \n",
    "    print(\"----------------------------------------------------------\")\n",
    "    print(\"Finsihed writing\")\n",
    "    print(\"Current time \" + str(datetime.datetime.now()))\n",
    "    \n",
    "   \n",
    " # end counting time\n",
    "end_time = time.time()                   \n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef17203b",
   "metadata": {},
   "source": [
    "# Municipality leaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede5b513",
   "metadata": {},
   "source": [
    "...because they were left out in the first run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f75f0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "users = pd.read_excel('./leaders_df/KOVid_15092022.xlsx', 'Sheet2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "569b4e02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows 156\n",
      "Currently done rows count 0\n",
      "Currently done rows count 20\n",
      "Currently done rows count 40\n",
      "Currently done rows count 60\n",
      "Currently done rows count 80\n",
      "Currently done rows count 100\n",
      "Currently done rows count 120\n",
      "Currently done rows count 140\n",
      "--- 61.87808704376221 seconds ---\n"
     ]
    }
   ],
   "source": [
    "twitter_names = []\n",
    "follower_count = []\n",
    "tweet_count = []\n",
    "last_tweet_times = []\n",
    "\n",
    "# start counting time\n",
    "start_time = time.time()\n",
    "print(\"Total rows\", len(users))\n",
    "for i,row in users.iterrows():\n",
    "    current_name = ''\n",
    "    current_follower_count = None\n",
    "    current_tweet_count = None\n",
    "    current_last_tweet_time = None\n",
    "    \n",
    "    if (i % 20 == 0):\n",
    "        print(\"Currently done rows count\", str(i))\n",
    "\n",
    "    # This .items(1) takes the first match\n",
    "    for cursor_user in tweepy.Cursor(api.search_users, q=row['nimi']).items(1):\n",
    "        current_name = cursor_user.screen_name\n",
    "        current_follower_count = cursor_user.followers_count\n",
    "        current_tweet_count = cursor_user.statuses_count\n",
    "        if hasattr(cursor_user, 'status'):\n",
    "            current_last_tweet_time = cursor_user.status.created_at\n",
    "    \n",
    "    twitter_names.append(current_name)\n",
    "    follower_count.append(current_follower_count)\n",
    "    tweet_count.append(current_tweet_count)\n",
    "    last_tweet_times.append(current_last_tweet_time)\n",
    "\n",
    "# end counting time\n",
    "end_time = time.time()                   \n",
    "print(\"--- %s seconds ---\" % (end_time - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55781049",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users = users\n",
    "df_users['twitter_usernames'] = twitter_names\n",
    "df_users['twitter_followers'] = follower_count\n",
    "df_users['twitter_tweet_count'] = tweet_count\n",
    "df_users['last_tweet_time'] = last_tweet_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dadf45f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = []\n",
    "\n",
    "for i, row in df_users.iterrows():\n",
    "    if pd.isna(row['last_tweet_time']):\n",
    "        years.append(row['last_tweet_time'])\n",
    "        continue\n",
    "    element = datetime.datetime.strptime(str(row['last_tweet_time']),\"%Y-%m-%d %H:%M:%S%z\")\n",
    "    years.append(element.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b234d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users['last_tweet_year'] = years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "eeb8a5b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_usernames = []\n",
    "\n",
    "for idx, user in df_users.iterrows():\n",
    "    username = user['twitter_usernames']\n",
    "    tweet_count = user['twitter_tweet_count']\n",
    "    last_tweet_year = user['last_tweet_year']\n",
    "\n",
    "\n",
    "    user_has_no_username = username == '' or pd.isna(username) # check if twitter username exists for a certain person\n",
    "    user_has_no_tweets = tweet_count == 0 # check if user has tweets\n",
    "    user_has_not_tweeted_lately = pd.isna(last_tweet_year) or int(last_tweet_year) < 2022 # check if last tweet made in 2022\n",
    "    if user_has_no_username or user_has_no_tweets or user_has_not_tweeted_lately:\n",
    "        continue\n",
    "        \n",
    "    valid_usernames.append(username)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cda42a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_users.to_csv('kov_useres_twitter_df.csv', encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ba6ccdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(valid_usernames).to_csv('kov_cleaned_twitter_usernames.csv', encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
